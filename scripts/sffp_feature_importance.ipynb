{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f14b48-b47a-4847-9756-44702a97d3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xlsxwriter\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.ensemble import RandomForestRegressor  \n",
    "from sklearn.metrics import mean_squared_error  \n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sens_up2_first_fp import get_cum_sens_from_1st_occ_df, get_tps_frac_bef_1st_fp_from_1st_occ_df, cum_sens_dist, auc_tps_bef_1st_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508c7f39-4543-4239-b2a6-21003d9162d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/\"\n",
    "pi_df = pd.read_csv(f\"{data_dir}/processed/avg_intra_fam_pident.tsv\", sep=\"\\t\") #pi means percentage identity\n",
    "ss_info_df = pd.read_csv(f\"{data_dir}/processed/ss_info_pfam.tsv\", sep=\"\\t\")\n",
    "cn_df = pd.read_csv(f\"{data_dir}/processed/avg_contact_num.tsv\", sep=\"\\t\")\n",
    "plddt_df = pd.read_csv(f\"{data_dir}/processed/pfam_avg_plddt.tsv\", sep=\"\\t\")\n",
    "plddt_df[\"size\"] = plddt_df[\"seed_id\"].str.split(\"-\", expand=True)[2].astype(int) - plddt_df[\"seed_id\"].str.split(\"-\", expand=True)[1].astype(int) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fe03e9-a0b3-4ad1-8e46-11ba43235fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "protperties_df = pi_df.merge(ss_info_df, on=\"seed_id\").merge(cn_df, on=\"seed_id\").merge(plddt_df, on=\"seed_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d707edd-babe-4637-9ca8-606606d2c453",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "first_occ_dict = {}\n",
    "\n",
    "all_tsv_files = glob.glob(f\"{data_dir}/processed/first_label_occ/*_B*.tsv\")\n",
    "tools = {'cif_cut', 'mm', 'reseek', 'tm'} \n",
    "file_paths_tool_dict = {x: [y for y in all_tsv_files if x in y] for x in tools} \n",
    "\n",
    "for tool, tool_tsv_paths in file_paths_tool_dict.items():\n",
    "    first_occ_list = []\n",
    "    for tsv_path in tool_tsv_paths:\n",
    "        tsv_df = pd.read_csv(tsv_path, sep=\"\\t\")\n",
    "        first_occ_list.append(tsv_df)\n",
    "    first_occ_dict[tool] = pd.concat(first_occ_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8512d61c-5fa3-45ec-b212-d60775e512ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_sens_up2first_fp_dict_fam = {tool: get_tps_frac_bef_1st_fp_from_1st_occ_df(first_occ_dict[tool])[[\"seed_id\", \"tp_bef_fp_frac_pfam\"]] for tool in first_occ_dict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57c8b56-02ca-4b4c-a4f6-d08e83e193ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_prop = {tool: frac_sens_up2first_fp_dict_fam[tool].merge(protperties_df, on=\"seed_id\") for tool in tools}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877de88b-d05d-482f-8a56-87a328c3ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data_df):\n",
    "    \"\"\"Trains a random forest for each model and shows the importance of the features\"\"\"\n",
    "    # Assuming the last 8 columns are features and the second column is the target  \n",
    "    X = data_df.iloc[:, -8:]     # Features (last 8 columns)  \n",
    "    y = data_df.iloc[:, 1]       # Target (second column)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    # Initialize the model  \n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)  \n",
    "    \n",
    "    # Fit the model  \n",
    "    rf_model.fit(X_train, y_train)\n",
    "    # Make predictions  \n",
    "    y_pred_train = rf_model.predict(X_train)\n",
    "    y_pred_test = rf_model.predict(X_test)  \n",
    "    \n",
    "    # Calculate Mean Squared Error  \n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "    \n",
    "    importances = rf_model.feature_importances_  \n",
    "    # Create a DataFrame for visualization  \n",
    "    importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances})  \n",
    "    importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    return {\"model\":rf_model, \"mse_train\": mse_train, \"mse_test\": mse_test, \"feature_importance\": importance_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2825ddb8-01a6-40b0-b3e0-28bb0457efd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_information = {}\n",
    "for tool, data_df in perf_prop.items():\n",
    "    tool_information[tool] = train_model(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee516beb-3f08-44d3-b7bb-a02db8296aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name_mapping = {\"avg_contact_num\": \"Average contact number\",\n",
    "                \"avg_intra_fam_pident\": \"Average sequence identity with other family members\",\n",
    "                \"size\": \"Domain length\",\n",
    "                \"avg_plddt\" : \"Average pLDDT\",\n",
    "                \"len_norm_tr_count\": \"The number of transitions in the secondary structure state normalized by the domain length\",\n",
    "                \"c_frac\": \"Coil fraction\",\n",
    "                \"e_frac\": \"Sheet fraction\",\n",
    "                \"h_frac\": \"Helix fraction\"}\n",
    "tool_name_mapping = {'cif_cut': \"Foldseek (cif_cut)\", 'mm': \"MMseqs\", 'reseek': \"Reseek\", 'tm': \"TM-align\"} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc393b1d-36a4-4aa3-8af4-e02b6b3293a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter(f'{data_dir}/processed/feature_importance.xlsx', engine='xlsxwriter')\n",
    "\n",
    "\n",
    "for tool, model_data in tool_information.items():\n",
    "    feature_importance_df = model_data[\"feature_importance\"]\n",
    "    feature_importance_df[\"Feature\"] = feature_importance_df[\"Feature\"].apply(lambda x: feature_name_mapping[x])\n",
    "    feature_importance_df.to_excel(writer, sheet_name=tool_name_mapping[tool], index=None)\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
