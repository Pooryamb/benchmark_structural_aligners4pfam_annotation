{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e68d6a6-ab37-4d53-9d5e-50adeb8ff724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "from headers import headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216e2245-4b7d-4eb8-9693-ab73b34a20a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_full_names = {'fs_10': 'Foldseek', \n",
    "                    'fs_exh': 'Foldseek (without prefilter)', \n",
    "                    'hmmscan_10': \"HMMER\", \n",
    "                    'hmmscan_exh': \"HMMER (without prefilter)\", \n",
    "                    'mm_10': \"MMseqs\", \n",
    "                    'mm_exh': \"MMseqs (without prefilter)\",\n",
    "                    'reseek_10_fast': \"Reseek (fast)\", \n",
    "                    'reseek_10_sens': \"Reseek (sensitive)\",  \n",
    "                    'reseek_exh': \"Reseek (without prefilter)\",\n",
    "                    'tm_exh': \"TM-align\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d69f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "# Blue, Orange, Green, Red, Purple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2574036",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/processed/f1_data.pkl\", 'rb') as file:\n",
    "    f1_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b2a0d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0272aa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tool in f1_data.keys():\n",
    "    print(tool)\n",
    "    print(f1_data[tool][\"max_f1_evalue_bin\"])\n",
    "    #df = f1_data[tool][\"precision_vs_recall\"]\n",
    "    #print(df.tail(1)[\"evalue_bin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d583760",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_data[\"fs_10\"]['f1_ci_lower'])\n",
    "print(f1_data[\"fs_10\"]['f1_ci_upper'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afece4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_data[\"fs_10\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc5d4be-bc06-4b21-ad3e-f624061816af",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_perf_dict = {x:add_performance4different_evalue_cutoffs(y) for x,y in method_df_dict.items() if \"tm\" not in x}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478fcbb8-00f8-44c3-9cc3-210e79b3c46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dir = \"../figures/\"\n",
    "os.makedirs(fig_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860e69ac-40d3-4aa0-9e6b-7fdceeca8bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6), dpi=300)\n",
    "\n",
    "all_f1_scores = {}\n",
    "for key, df in discrete_perf_dict.items():\n",
    "    # Calculate F1 scores\n",
    "    f1_scores = 2 * (df[\"precision\"] * df[\"recall\"]) / (df[\"precision\"] + df[\"recall\"])\n",
    "    all_f1_scores[key] = f1_scores\n",
    "    # Find the index of maximum F1 score\n",
    "    max_f1_idx = f1_scores.idxmax()\n",
    "    max_f1_value = f1_scores.max()\n",
    "    \n",
    "    # Get the precision and recall at max F1\n",
    "    max_precision = df.loc[max_f1_idx, \"precision\"]\n",
    "    max_recall = df.loc[max_f1_idx, \"recall\"]\n",
    "    \n",
    "    # Plot the precision-recall curve\n",
    "    plt.plot(df[\"precision\"], df[\"recall\"], label=f'{tools_full_names[key]} (F1={max_f1_value:.3f})')\n",
    "    \n",
    "    # Highlight the best F1 point\n",
    "    plt.scatter(max_precision, max_recall, marker='*', s=100, zorder=5)\n",
    "    \n",
    "    # Optional: Annotate the point\n",
    "    plt.annotate(f'', \n",
    "                xy=(max_precision, max_recall),\n",
    "                xytext=(5, 5), textcoords='offset points',\n",
    "                fontsize=8, alpha=0.7)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Precision')\n",
    "plt.ylabel('Recall')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(f\"{fig_dir}/precision_recall_split_vs_split.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd88c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_recall_evalue = {x: find_prec_recall_vs_evalues(y) for x,y in method_df_dict.items()}\n",
    "prec_recall_evalue = {x: y[y[\"row_num\"] >= 500] for x,y in prec_recall_evalue.items()}\n",
    "\n",
    "plt.figure(figsize=(10, 6), dpi=300)\n",
    "\n",
    "all_f1_scores = {}\n",
    "for key, df in prec_recall_evalue.items():\n",
    "    \n",
    "    # Plot the precision-recall curve\n",
    "    plt.plot(df[\"precision\"], df[\"recall\"], label=f'{tools_full_names[key]}')\n",
    "    \n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Precision')\n",
    "plt.ylabel('Recall')\n",
    "plt.grid(True, alpha=0.3)\n",
    "#plt.savefig(f\"{fig_dir}/precision_recall_split_vs_split.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f046029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "what to do:\n",
    "    add_f1\n",
    "    find the max f1 for each df and its e-value threshold\n",
    "    interp recall from precision using each bootstrap\n",
    "    and return the interpolated line\n",
    "prec_recall_evalue[\"tm_exh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7401e0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prec_recall_evalue[\"reseek_exh\"]\n",
    "df[\"f1\"] = 2*df[\"precision\"]*df[\"recall\"]/(df[\"precision\"] + df[\"recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f7b73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax_row = df[\"f1\"].argmax()\n",
    "print(argmax_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cd86b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[argmax_row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6246836",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"f1\"].max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
